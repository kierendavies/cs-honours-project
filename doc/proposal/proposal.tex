%TC:macro \subtitle [header]
%TC:newcounter todo Number of TODOs
%TC:macro \todo [option:ignore]
%TC:macrocount \todo [todo]

\documentclass[draft]{sig-alternate}
\makeatletter
\def\@copyrightspace{\relax}
\makeatother

\usepackage[inline]{enumitem}
\usepackage{pgfgantt}
\usepackage[figuresright]{rotating}
\usepackage{tabularx}

\usepackage[english]{babel}
\usepackage[english]{isodate}
\cleanlookdateon

\usepackage{ifdraft}
\usepackage{xifthen}
\usepackage{soul}
\usepackage{xcolor}
\newcommand{\todo}[1][]{\ifdraft{\ifthenelse{\isempty{#1}}{\hl{(TODO)}}{\hl{(TODO: #1)}}}{}}

% This has to go in the preamble to not get counted by texcount
\numberofauthors{2}

\begin{document}

\title{Ontology Unit Testing}
\subtitle{Project Proposal}
\author{
  \alignauthor
  Ameerah Allie\\
    \affaddr{University of Cape Town}\\
    \email{ameerah.allie@gmail.com}
  \alignauthor
  Kieren Davies\\
   \affaddr{University of Cape Town}\\
   \email{kieren@kdavi.es}
}
\date{17 May 2016}
\maketitle

\begin{abstract}
  Test-driven development has been adopted in software engineering where it has improved code complexity and understandability. Efforts into introducing test-driven development and unit testing in ontologies have been made to improve the development and quality of ontologies. Current efforts into this are not comprehensive enough yet in the variety of test types that are covered which are also only proven correct empirically, while reasoner performance and use are not optimised and poorly understood. This project addresses these problems by (1) developing more tests to cover a larger test set and proving their correctness strictly, and (2) examining reasoner performance for different reasoners on the already-existing set of unit tests. This allows for better ontology quality through more tests made available for unit testing, covering testing of more parts of an ontology. It also improves the test-driven development process for ontologies by testing the performance of different reasoners on unit test types and allowing for better choices regarding the reasoner to be made in test-driven development.
\end{abstract}

\section{Introduction}

Test-driven development is a methodology derived from Extreme Programming. It is a test-first approach to programming that requires consistent unit testing of code throughout the development phase. Ontology development has fewer mature methodologies. In these methodologies, more is made of the process of development as a whole than \textit{ontology authoring} concerning which axioms to add and how these axioms ought to be added. To test, ontology developers usually employ a test-last approach by inserting axioms and checking with the reasoner that it does not create any inconsistencies. This does not guarantee that satisfactory ontologies are produced. The benefits of test-driven development when applied to software engineering, like improved quality of code and decreased complexity, are desirable for ontology development also.

Test-driven development for ontologies was introduced by Keet and {\L}awrynowicz \cite{DBLP:journals/corr/KeetL15} as a low-level solution to this problem. The TDDOnto tool was developed as a plugin to Prot\'eg\'e \cite{DBLP:conf/dlog/LawrynowiczK16}. This introduced the idea of unit tests from test-driven development to ontologies by defining tests for the introduction of each new axiom. Other work has also been done into unit testing for ontologies without developing the test-driven methodolgy itself.

This project expands on that work by defining more tests to cover a greater scope of unit tests and testing reasoner performance on unit tests. This includes defining new tests and proving correctness for them theoretically. The benchmarking aspect requires that different reasoners are employed in the development of ontologies for different types of unit tests. These will not include the new set of unit tests to allow for project concurrency - allowing both parts to be carried out simultaneously. This allows for better understanding of how reasoners perform. 

The process described above does not include test subjects or external human involvement. This eases ethical conerns about the project, with the only major concern being a legal one of proper use of data and software. The two distinct parts, unit test development and benchmarking, will be carried out concurrently.

These developments into unit testing have the broader effects of expanding the scope of test-driven development for ontologies and paving the way for streamlining the process by creating an understanding of reasoner performance to allow different reasoners to be used for different types of ontologies or the axioms contained within them.

\section{Project Description}

\subsection{Project Background}

\todo[Ameerah: Reference better]

Test-driven development is a methodology derived from Extreme Programming. It is a test-first approach to programming that requires consistent testing throughout the development phase. This is shown to improve complexity and understandability of code, thereby improving code quality. Ontology development lacks mature methodologies to assist the process of development. Comparatively, more is made of the process of development as a whole than \textit{ontology authoring} concerning which axioms to add and how these axioms ought to be added. There is no existing testbed for the addition of axioms into ontologies to ensure correctness. The benefits of test-driven development when applied to software engineering, like improved quality of code and decreased complexity, are desirable for ontology development also. Currently, tests are not applied throughout the ontology development process. Instead tests are applied afterwards by running the reasoner on the ontology and checking for inconsistencies and errors. This does not guarantee that satisfactory ontologies are produced.

Test-driven development for ontologies was introduced by Keet and {\L}awrynowicz \cite{DBLP:journals/corr/KeetL15} as a low-level solution to this problem. The TDDOnto tool was developed as a plugin to Prot\'eg\'e \cite{DBLP:conf/dlog/LawrynowiczK16}. This introduced the idea of unit tests from test-driven development to ontologies by defining tests for the introduction of each new axiom. Tests were defined and applied to the TBox for terminological data. No RBox (reasoner) tests were run as some OWL 2 features were not covered by OWL-BGP (used in implementation) and there is still scope for additional TBox and ABox tests. TBox tests were, on average, found to have been faster than the ABox tests with the exception of tests concerning disjointness. The research into this field is still in its early stages.

\subsection{Project Significance}

Since this kind of low-level ontology authoring has not been widely researched, our efforts into it could improve the ontology authoring process for many ontology engineers. Generally, test-driven development for ontology engineering could improve the overall quality of ontologies that are being developed while ensuring that others who attempt to use those ontologies as a base for theirs may find those ontologies easier to understand and use. Mature development processes would also encourage wider adoption of ontologies in business and industry as a solution to problems. Unit testing for ontologies in particular has been said by Vrande{\v{c}}i{\'c} and Gangemi \cite{DBLP:conf/otm/VrandecicG06} to make the code less tightly-coupled and easier to integrate and refactor.

Our project in particular does not change the methodology laid out by Keet and {\L}awrynowicz \cite{DBLP:journals/corr/KeetL15} but refines and extends some of the ideas within it. Part of the project includes extending the set of tests defined for TDDOnto\todo[Kieren: comment from Maria - "be more specific: how?"]. This includes proving correctness for these tests. If successful, it has the impact of more unit tests being made available for more types of axioms. This allows ontology developers to test for correctness of more types of axioms and apply the test-driven development methodology more broadly to their ontologies. It has the possibility of facilitating regression testing of ontologies and allow for testing of ontologies in a manner that is well-defined and simple to use \cite{DBLP:conf/otm/VrandecicG06}.

Test-driven development speed can be improved by efficient reasoner choices being made for testing. This includes better reasoner choices for specific types of axioms. The other part of this project includes, primarily, experimenting with reasoners applied to a set of ontologies and the benchmarking of these tests. This involves applying different reasoners to test their performance in comparison to the reasoner originally used, HermiT, and categorically determining which reasoners are more efficient and for which axioms or tests. In addition to improving reasoner choices for test-driven development, it has general implications for reasoner choices beyond test-driven development in ontology development.

\section{Related Work}

The literature contains only three prior attempts to implement unit tests for ontologies.  We will be basing our work off TDDOnto, as it is the only suitable implementation.

Tawny-OWL is a library which includes programmatic ontology testing \cite{DBLP:journals/corr/WarrenderL15}.  We do not consider it because it implements only a very small set of tests, and in isolation they offer little abstraction over the OWL API.

\textsc{Scone} \todo[Kieren: comment from Maria - a little more description would have been better. Like, scone does x; we aim to do y, which precedes/serves at the back end of x] is an ontology testing tool which is oriented towards behaviour-driven development \cite{SconeUserGuide}.  We do not consider it because it uses a sophisticated domain-specific language to specify tests, and focusses on testing human-understandable scenarios rather than complex axioms.

Vrande\v{c}i\'c and Gangemi \cite{DBLP:conf/otm/VrandecicG06} propose a means of testing ontologies but do not present an implementation.  They do however suggest the beginnings of a formal model of testing.  It will need to be extensively developed to be useful to this project.  One possible extension is the use of autoepistemic operators, which have been use to perform closed-world reasoning within ontologies \cite{DBLP:conf/owled/GrimmM05}.

Parsia et al.\ \cite{DBLP:conf/semweb/ParsiaMGGS15} compared 14 reasoners by measuring performance of classification, consistency checking, and realisation in OWL 2 DL and EL.  The results of this inform the choice of reasoners for benchmarking.

\section{Problem Statement}

\todo[Kieren: I rephrased this as problem, not benefits and aims; please check this is correct]

An initial set of unit tests for test-driven development in ontology development, described in the previous section, was specified and implemented in the TDDOnto tool. This and other available tools do not support a fully comprehensive list of tests. Currently, only a limited number of unit tests have been defined. There is no systematic coverage of all OWL features. ABox axioms are not implemented and RBox axioms are not defined \todo[Kieren: please check this statement is correct]. Their correctness has only been proven empirically. Proof of correctness thus needs to be done. There needs to exist a larger set of unit tests to cover a greater variety of types of axioms to improve the test-driven development methodology scope.

Furthermore, the performance of reasoners in reasoner-based tests are poorly understood. It is not well understood which reasoners perform better on certain types of axioms or why the perform better. It is not known which reasoner performs better than others on each of the specific unit test implementations in real ontologies. As such, test performance may not be optimal, especially in terms of speed as only one type of reasoner is used which may not be appropriate for all unit test implementations.

\section{Project Design}

\subsection{Procedures and Methods}

To devise new unit tests, we will draw inspiration from TDDOnto.  We will include some of those \todo[Kieren: Maria questions why only some of them] which TDDOnto explicitly excludes, such as RBox tests, and also extrapolate to more complex compound axioms.  We will also introduce more unit test outcomes by characterising failure modes; for example, when vocabulary is missing, or when the missing axiom may be added to the ontology without causing inconsistency.

In order to prove the correctness of unit tests, we must first develop a formal model, and then identify which questions can be directly answered by a reasoner in terms of this model.  The model will then be used to prove the correctness and completeness of each test algorithm.

After this, each test will be implemented as an addition to TDDOnto.  They can then be further verified empirically.

Benchmarking of reasoners will employ the following experimental method:
\begin{enumerate}[noitemsep]
  \item Gather ontologies to be used for testing
  \item Implement or obtain algorithm to automatically generate unit tests
  \item Implement or obtain benchmark wrapper script
  \item Check script and unit test generation by benchmarking one test type in one ontology
  \item Identify and select independent variables to control, e.g.\ DL profile, ontology size
  \item Modify script to benchmark every combination of chosen variables
  \item Perform benchmarks and record results
  \item Perform an analysis of variables on the resulting data
\end{enumerate}

\subsection{Project Issues and Difficulties}

The difficulty in the first part of the project, extending the testbed, is formalising mathematically what unit tests in ontology development are and defining and proving correctness for the additional tests in the extended testbed. While these are defined goals, they are unlikely to be trivial. Formalising these tests and proving correctness may be too difficult. There is also the unlikelihood that no consistent formalisation exists for these tests which complicates the task of proving correctness. This is being developed as an extension of the TDDOnto testbed but there may be the possibility that this new set of sets may be too complex too be incorporated into TDDOnto. In this case, developing a new tool may not be feasible in the timeframe of this project. As such, the tests still have value as being valid and correct unit tests for ontology development but would lack proper implementation.

The second part of the project concerns itself primarily with benchmarking various reasoners. The difficulty around this problem would be integrating different reasoners for use with the current TDDOnto infrastructure and set-up, including the OWL API and OWL-BGP. This may limit the number of reasoners chosen to ones that are compliant, reducing the set of reasoners tested and the impact of the experiment. Controlling for variables like the reasoner or types of test or axiom when running the test over a large set of ontologies would necessitate scripting to make the running of tests and collection of its data manageable. It may also be resource-heavy and time-consuming which could be solved by possibly negotiating time on faster resources of the University of Cape Town.

\section{Anticipated Outcomes}

Here we state the outcomes we anticipate for the project. They will serve as means of measuring the success of the final outcomes of the project.

\subsection{Project Outcome}

As stated previously, the project consists of extending the test suite of unit tests that can be applied to ontologies for unit testing. This is not a software development project so it cannot be measured by number and quality of deliverables successfully developed. Instead, we expect that correctness will be proven which has not been done yet for any unit tests for ontologies. This will be done for an already-described test and also for the new tests in the extended test suite for tests we have devised.

Benchmarking also does not produce a software deliverable. Instead, it produces a set of data on reasoner performance for specific types of unit tests. This data will be analysed to test for statistically significant results. This informs choices for reasoners in test-driven development for ontologies for specific unit tests and may improve test speeds. There may be scope to prototype a system that incorporates running the best reasoner for a specific unit test and, despite start-up time of reasoners increasing, decrease overall runtime. This is left as an additional but not necessary task.

Overall, this has the effect of improving the test-driven development for ontology engineering methodology with a greater test suite (with proven correctness) and measured reasoner performance. We hope this will provide some encouragement to ontology developers to employ the test-driven development methodology which may improve their ontologies.

\subsection{Success Factors}

Success for correctness will be measured simply by whether or correctness has been sufficiently proven and if the proof is conclusive and correct itself. A number of new tests should be defined for unit testing. This will include composition of different types of axioms. This will be successful if the test suite is sufficiently expanded.

The outcome of the benchmarking tests will prove if, at all, there is a best (fastest) reasoner for a specific type of axiom. This is measured by speed of the reasoner. Success of the project does not depend on whether or not the results prove, with statistical significance, that one reasoner is better than another for reasoning over a specific type of axiom. If reasoners are found to be equal in performance, then this still proves that choice of reasoner in ontology development is not affected by speed. Success of the project is instead measured by whether or not these tests are successfully carried out and analysed. This can be ensured by making fair, unbiased tests by blocking for the identified independent variables (for example, reasoners used) to ensure that the tests are valid.

\section{Project Plan}

\subsection{Deliverables and Milestones}

The following deliverables have been prescribed:
\printyearoff
\begin{description}[noitemsep,font=\normalfont,labelwidth=60pt,leftmargin=64.5pt]
  \item[\printdate{2016-05-17}] Proposal
  \item[\printdate{2016-06-08}] Revised proposal
  \item[\printdate{2016-06-10}] Web presence
  \item[\printdate{2016-07-18}] Initial feasibility demonstration
  \item[\printdate{2016-07-22}] Background section of paper
  \item[\printdate{2016-08-29}] Paper plan
  \item[\printdate{2016-09-20}] First experiment, with section in paper
  \item[\printdate{2016-09-29}] Final experiment, with section in paper
  \item[\printdate{2016-10-04}] Final implementation and testing, with \\ sections in paper
  \item[\printdate{2016-10-11}] Complete outline of paper
  \item[\printdate{2016-10-18}] Final draft of paper
  \item[\printdate{2016-10-28}] Final submission of paper
  \item[\printdate{2016-10-31}] Final source code
  \item[\printdate{2016-10-31}] Final demonstration
  \item[\printdate{2016-11-07}] Poster
  \item[\printdate{2016-11-11}] Website
  \item[\printdate{2016-11-14}] Reflection paper
\end{description}

In addition, we have set the following milestones, which approximately describe the sequence in which work must be done:
\begin{enumerate}[noitemsep]
  \item Formal model of ontology unit tests
  \item First proof of correctness (of new or existing test)
  \item First new test implementation
  \item Final suite of new tests, with implementation and proof of correctness
  \item Reproducible benchmark of one reasoner against one test
  \item Final choice of controlled independent variables for benchmarking
  \item Completion of benchmarks over all variables
  \item Completion of data analysis
\end{enumerate}

\subsection{Resources}

The project requires the following software:
\begin{itemize}[noitemsep]
  \item Prot\'eg\'e ontology editor
  \item TDDOnto plugin for Prot\'eg\'e
  \item Various reasoners
  \item Scripts for automated testing
\end{itemize}

Prot\'eg\'e is required for editing ontologies. This may include the addition and removal of axioms. TDDOnto is the basis for this project. The original software will be used as the basis of the test suite extension, including its source code. Reasoners, like HermiT and Konclude, will also be used in benchmarking and their performance will be measured but will not require editing of the original source code. The scripts for automated test execution would need to be obtained from Dr.\ A.\ {\L}awrynowicz or written by ourselves. There is no other human participation in the project. This limits the human or labour resources required.

The data used will be ontologies that are extracted from the TONES mirror from the OntoHub repository. These ontologies will be the 82 ontologies from the original TDDOnto tests whose features are OWL 2 compliant.

If the reasoner tests prove to be too computationally intensive for the machines on which we are developing, time may need to be negotiated for use of UCT's grid cluster resource. This is not a requirement at this stage but is a foreseeable use of resources. Our local machines are sufficient for every other task for this project.

\subsection{Timeline}

The project consists of the following primary tasks:
\begin{enumerate}[noitemsep]
  \item Finalise proposal
  \item Create website
  \item Demonstrate feasibility of
  \begin{enumerate}[nosep]
    \item new unit tests with proofs of correctness
    \item benchmarking reasoners
  \end{enumerate}
  \item Create comprehensive suite of new unit tests, with proofs and implementation.
  \item Benchmark reasoners with new and existing unit tests
  \item Perform statistical analysis on benchmark results
  \item Write paper
\end{enumerate}
\todo[repetition]
The full list of tasks and subtasks has been scheduled in a Gantt chart in Figure \ref{fig:gantt}.

\begin{sidewaysfigure*}
  \caption{Timeline Gantt chart}
  \label{fig:gantt}
  \vspace{6pt}
  \hspace{-1.5cm}
  \input{gantt}
\end{sidewaysfigure*}

\subsection{Work Allocation}

The project is separated into two distinct parts:
\begin{enumerate*}[label=(\arabic*)]
  \item the addition of unit tests to the test suite and proof of their correctness, and
  \item benchmarking of reasoner performance against the ontologies and the original test suite.
\end{enumerate*}
The former will be done by Kieren Davies and the latter by Ameerah Allie. They represent two distinct project divisions that have no inter-project dependencies \todo[the plan suggests otherwise]. Other tasks, like website creation and maintenance and the eventual poster, will be shared equally amongst the team.

\subsection{Risks}

An analysis of risks is presented in Table \ref{tab:risks}.

\begin{table*}
  \caption{Analysis of risks}
  \label{tab:risks}
  \vspace{6pt}
  \setlength{\extrarowheight}{4pt}
  \begin{tabularx}{\textwidth}{XcX}
    Risk & Likelihood & Mitigation \\ \hline
    Benchmarking is too slow to run on a desktop computer. &
    High &
    Use high-performance hardware in the UCT grid cluster, and run benchmarks in parallel. \\
    Developing a formal model of ontology unit tests is too difficult. &
    Medium &
    Seek help from experts in description logic and model theory. \\
    Benchmarking scripts are not available from Dr.\ {\L}awrynowicz. &
    Low &
    Write scripts from scratch, and reduce the scope of the experiment if necessary due to time constraints. \\
    Benchmarking scripts cannot be adapted to accomodate desired controlled variables. &
    Low &
    Consult Dr.\ {\L}awrynowicz.  If necessary, rewrite the scripts or reduce the scope of the experiment. \\
    New unit tests cannot be implemented with the same technologies used in TDDOnto. &
    Low &
    Investigate using another tool such as Tawny-OWL, or developing a new tool.
  \end{tabularx}
\end{table*}

\section{Ethical, Professional and Legal Issues}

This project does not include subjects for testing. As such, there are no ethical considerations regarding treatment of others or the application of the results of the project.

We plan to use various software in the course of this project. Legal issues arise from this: software must be used lawfully and we may not be in contravention of any of the policies of use.

We plan to use both Prot\'eg\'e\footnote{http://protege.stanford.edu/} and the TDDOnto tool\footnote{https://semantic.cs.put.poznan.pl/wiki/aristoteles/doku.php} for this project. Prot\'eg\'e is an open source tool for ontology editing and a framework for building intelligent systems. It is open source under the BSD-2 clause license\footnote{https://github.com/protegeproject/webprotege/blob/master/license.txt}. We will use Prot\'eg\'e within the terms specified. TDDOnto is a plugin for Prot\'eg\'e made available online. It is not open source but is available for use. Verbal permission was given by Dr.\ C.\ M.\ Keet, co-creator of the tool and the supervisor for this project, to use the software.

Additionally, the benchmarking part of this project requires scripting to automate the tests being run and its data being collected. Permission to use and modify Dr.\ A.\ {\L}awrynowicz's scripts was obtained. Benchmarking also requires the use of reasoners. These reasoners will not be edited but simply used for their reasoning function. They are freely available for use and will be used within their specified intents for use.

No additional software is currently expected to be used. Given that all the software we intend to use is open source or proprietary with permission granted, there are no issues regarding licensing. It presents no legal issues.

Ethical concerns may be raised about the proper use of data. Benchmarking requires a sample set of ontologies to apply the tests to and reason over. The same ontologies that the original TDDOnto experiment used \cite{DBLP:conf/dlog/LawrynowiczK16} and further ontologies which must still be sourced will be used. These include ontologies from the TONES mirror at OntoHub\footnote{https://ontohub.org/repositories} which are made available for public use. OntoHub is an open ontology repository that enables the free download and use of the ontologies it holds. As such, there are no restrictions on use of the data and permission for use is not required. It presents no ethical, professional or legal issues.

Professionally, the group members undertake to behave respectfully towards each other and any parties that may be onvolved in this project.

It is the policy of the University of Cape Town that all software produced within the capacity of the project is the copyright of the university. It also must be published under a Creative Commons license. We will adhere to the university's Intellectual Property policy. This includes publishing the results of the performance test data.

\bibliographystyle{abbrv}
\bibliography{references}
\end{document}
