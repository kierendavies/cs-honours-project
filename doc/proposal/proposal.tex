%TC:macro \subtitle [header]
%TC:newcounter todo Number of TODOs
%TC:macro \todo [option:ignore]
%TC:macrocount \todo [todo]

\documentclass[draft]{sig-alternate}
\makeatletter
\def\@copyrightspace{\relax}
\makeatother

\usepackage{enumitem}

\usepackage{pgfgantt}
\usepackage[figuresright]{rotating}

\usepackage{ifdraft}
\usepackage{xifthen}
\usepackage{soul}
\usepackage{xcolor}
\newcommand{\todo}[1][]{\ifdraft{\ifthenelse{\isempty{#1}}{\hl{(TODO)}}{\hl{(TODO: #1)}}}{}}

% This has to go in the preamble to not get counted by texcount
\numberofauthors{2}

\begin{document}

\title{Ontology Unit Testing}
\subtitle{Project Proposal}
\author{
  \alignauthor
  Ameerah Allie\\
    \affaddr{University of Cape Town}\\
    \email{ameerah.allie@gmail.com}
  \alignauthor
  Kieren Davies\\
   \affaddr{University of Cape Town}\\
   \email{kieren@kdavi.es}
}
\date{5 May 2016}
\maketitle

\section{Project Description}

\subsection{Project Background}

Test-driven development is an Extreme Programming methodology for development. It is a test-first approach to programming that requires consistent testing throughout the development phase. This is shown to improve complexity and understandability of code, thereby improving code quality. Ontology development lacks mature methodologies to assist the process of development. Comparatively, more is made of the process of development as a whole than \textit{ontology authoring} concerning which axioms to add and how these axioms ought to be added. There is no existing testbed for the addition of axioms into ontologies to ensure correctness. The benefits of test-driven development when applied to software engineering, like improved quality of code and decreased complexity, is desirable for ontology development also. Currently, tests are not applied throughout the ontology development process. Instead tests are applied afterwards by running the reasoner on the ontology and checking for inconsistencies and errors. This does not guarantee that satisfactory ontologies are produced.

Test-driven development for ontologies was introduced by Keet and {\L}awrynowicz \cite{DBLP:journals/corr/KeetL15} as a low-level solution to this problem. The TDDonto tool was developed as a plugin to Prot\'eg\'e \cite{DBLP:conf/dlog/LawrynowiczK16}. This introduced the idea of unit tests from test-driven development to ontologies by defining tests for the introduction of each new axiom. Tests were defined and applied to the TBox (terminalogical data) and ABox (assertional data). No RBox (reasoner) tests were run as some OWL 2 features were not covered by OWL-BGP (used in implementation) and there is still scope for additional TBox and ABox tests. TBox tests were, on average, found to have been faster than the ABox tests with the exception of tests concerning disjointness. The research into this field is still in its early stages.

\subsection{Project Significance}

Since this kind of low-level ontology authoring has not been widely researched, our efforts into it could improve the ontology authoring process for many ontology engineers. Generally, it test-driven development for ontology engineering could improve the overall quality of ontologies that are being developed while ensuring that others who attempt to use those ontologies as a base for theirs may find those ontologies easier to understand and use. Mature development processes would also encourage wider adoption of ontologies in business and industry as a solution to problems. Unit testing for ontologies in particular has been said by Vrande{\v{c}}i{\'c} and Gangemi \cite{DBLP:conf/otm/VrandecicG06} to make the code less tightly-coupled and easier to integrate and refactor.

Our project in particular does not change the methodology laid out by Keet and {\L}awrynowicz \cite{DBLP:journals/corr/KeetL15} but refines and extends some of the ideas within it. Part of the project includes extending the set of tests defined for TDDOnto. This includes proving correctness for these tests. If successful, it has the impact of more unit tests being made available for more types of axioms. This allows ontology developers to test for correctness of more types of axioms and apply the test-driven development methodology more broadly to their ontologies. It has the possibility of facilitating regression testing of ontologies and allow for testing of ontologies in a manner that is well-defined and simple to use \cite{DBLP:conf/otm/VrandecicG06}.

The other part of this project includes, primarily, experimenting with reasoners applied to a set of ontologies and the benchmarking of these tests. This involves applying different reasoners to test their performance in comparison to the reasoner originally used, HermiT, and categorically determining which reasoners are more efficient and for which axioms or tests. This has the impact of improving test-driven development speed by allowing for efficient reasoner choices. This may also inform reasoner choices for specific types of axioms or tests for general purposes beyond test-driven development in ontologies.

\subsection{Project Issues and Difficulties}

The difficulty in the first part of the project, extending the testbed, is formalising mathematically what unit tests in ontology development are and defining and proving correctness for the additional tests in the extended testbed. While these are defined goals, they are unlikely to be trivial. Formalising these tests and proving correctness may be too difficult. There is also the unlikelihood that no consistent formalisation exists for these tests which complicates the task of proving correctness. This is being developed as an extension of the TDDOnto testbed but there may be the possibility that this new set of sets may be too complex too be incorporated into TDDOnto. In this case, developing a new tool may not be feasible in the timeframe of this project. As such, the tests still have value as being valid and correct unit tests for ontology development but would lack proper implementation.

The second part of the project concerns itself primarily with benchmarking various reasoners. The difficulty around this problem would be integrating different reasoners for use with the current TDDOnto infrastructure and set-up, including the OWL API and OWL-BGP. This may limit the number of reasoners chosen to ones that are compliant, reducing the set of reasoners tested and the impact of the experiment. Controlling for variables like the reasoner or types of test or axiom when running the test over a large set of ontologies would necessitate scripting to make the running of tests and collection of its data manageable. It may also be resource-heavy and time-consuming which could be solved by possibly negotiating time on faster resources of the University of Cape Town.

\section{Problem Statement}

\todo[central issue: aims, research questions/problems]

\todo[correctness]
\todo[``analytical research problem'', not a question]
\begin{quote}
  \begin{itemize}[leftmargin=0pt]
    \item Only a small set of unit tests have been described and implemented; it is desirable to have many more in order to test more complex scenarios.
    \item Existing implementations can only pass or fail; it is desirable to have more states to indicate missing vocabulary and possible inconsistencies.
    \item Proof of correctness does not exist for any unit test algorithms.
  \end{itemize}
\end{quote}

\todo[benchmarking]
\begin{quote}
  Which reasoner has the best performance on each of the unit test implementations?
\end{quote}

\section{Procedures and Methods}

\todo[correctness]
\todo[methods of analysis]
\todo[this is only an outline]
\begin{enumerate}[noitemsep]
  \item Create formal model of test assertions
  \item Prove correctness of an already-described test
  \item Describe new tests
  \item Prove correctness of new tests
  \item Implement
  \item Verify empirically---``test the tests''
\end{enumerate}

\todo[benchmarking]
\todo[this is only an outline]
\begin{enumerate}[noitemsep]
  \item Gather ontologies
  \item Implement automatic unit test generation (use Agnieszka's)---use valid vocabulary, pick axioms which are known to hold (or not)
  \item Run with default reasoner etc.\ to ensure it works and produces reasonable numbers
  \item Identify independent variables: reasoner, test type, ontology size, DL profile, \dots
  \item Iterate benchmark scipt over some or all combinations; ensure it runs within a reasonable amount of time---if not, tactfully prune variables
  \item Revise independent variables?
  \item Collate and analyse data
\end{enumerate}
If you want to be clever and propose/prototype a system to run tests with the best reasoner:
\begin{enumerate}[noitemsep,resume]
  \item Measure startup times of reasoners
  \item Measure initial classification times of ontologies with different size, DL profile, etc.
  \item Create lookup table of expected startup/classification times
  \item Design algorithm to minimise total time taken
  \item Implement
\end{enumerate}

\section{Ethical, Professional and Legal Issues}

\subsection{Software}

We plan to use both Prot\'eg\'e\footnote{http://protege.stanford.edu/} and the TDDonto tool\footnote{https://semantic.cs.put.poznan.pl/wiki/aristoteles/doku.php} for this project. Prot\'eg\'e was developed at Stanford University and is a free and open source tool for ontology editing and framework for building intelligent systems. It is open source under the BSD-2 clause license\footnote{https://github.com/protegeproject/webprotege/blob/master/license.txt}. We will use Prot\'eg\'e within the terms specified. TDDonto is a plugin for Prot\'eg\'e made available online. It is not open source but is available for use. Verbal permission was given by Dr.\ C.\ M.\ Keet, co-creator of the tool and the supervisor for this project, to use the software.

Additionally, the benchmarking part of this project requires scripting to automate the tests being run and its data being collected. To assist with this, we will ask for permission of Dr.\ A.\ {\L}awrynowicz to use and modify the script she used for the TDDOnto tests \cite{DBLP:conf/dlog/LawrynowiczK16}. If this is not a possibility, these will have to be written by ourselves. This is possible but more time-consuming. It also requires the use of reasoners, like HermiT or Konclude. These reasoners will not be edited but simply used for their reasoning function. They are freely available for use and will be used within their specified intents for use.

No additional software is currently expected to be used. Given that all the software we intend to use is open source or proprietary with permission granted, there are no issues regarding licensing. It presents no ethical, professional or legal issues.

\subsection{Data}

The tests for the benchmarking part of the project require a sample set of ontologies to apply the tests to and reason over. This presents a data use problem. The solution to this is to use the same 82 ontologies that the original TDDOnto experiment used \cite{DBLP:conf/dlog/LawrynowiczK16}. These were the OWL 82 ontologies from the TONES mirror at OntoHub\footnote{https://ontohub.org/repositories} after removing the ones with OWL 2 datatype compatability issues. By necessity, it removes ontologies with datatypes that cannot be resolved in OWL 2 DL to the set of ontologies within the scope of this project. OntoHub is an open ontology that enables the free download and use of the ontologies it holds. As such, there are no restrictions on use of the data and permission for use is not required. It presents no ethical, professional or legal issues.

\subsection{Publishing Work}

It is the policy of the University of Cape Town that all software produced within the capacity of the project is the copyright of the university. It also must be published under a Creative Commons license. We will adhere to the university's Intellectual Property policy. This includes publishing the results of the performance test data.

As there is no user testing involved in the project, no ethical clearance of the involvement of test subjects is required.

\section{Related Work}

\todo[efforts towards TDD]
\todo[unit test implementations]
\todo[correctness]
\todo[benchmarking]

\section{Anticipated Outcomes}

\todo[impact (towards TDD?)]
\todo[measuring success]

\todo[correctness]

\todo[benchmarking]

\section{Project Plan}

\subsection{Risks}

\todo[risks]

\subsection{Resources Required}

The project requires the following software:
\begin{itemize}
  \item Prot{\'e}g{\'e} ontology editor
  \item TDDOnto plugin for Prot{\'e}g{\'e}
  \item Various reasoners
  \item Scripts for automated testing
\end{itemize}

Prot{\'e}g{\'e} is requiring for editing ontologies. This may include the addition and removal of axioms. TDDOnto is the basis for this project. The original software will be used as the basis of the test suite extension, including its source code. Reasoners, like HermiT and Konclude, will also be used in benchmarking and their performance will be measured but will not require editing of the original source code. The scripts for automated test execution would need to be obtained from Dr A. {\L}awrynowicz or written by ourselves. There is no other human participation in the project. This limits the human or labour resources required.

The data used will be ontologies that are extracted from the TONES mirror from the OntoHub repository. These ontologies will be the 82 ontologies from the original TDDOnto tests whose features are OWL 2 compliant.

If the reasoner tests prove to be too computationally intensive for the machines on which we are developing, time may need to be negotiated for use of UCT's GPU cluster resource. This is not a requirement at this stage but is a foreseeable use of resources. Our local machines are sufficient for every other task for this project.

\subsection{Deliverables}

\todo[deliverables]

\subsection{Milestones}

\todo[milestones?]

\subsection{Work Allocation}

\todo[work allocation]

\subsection{Timeline}

\todo[timeline, Gantt chart]

Figure \ref{fig:gantt}

\begin{sidewaysfigure*}
  \caption{Timeline Gantt chart}
  \label{fig:gantt}
  \vspace{6pt}
  \hspace{-1.5cm}
  \input{gantt}
\end{sidewaysfigure*}

\bibliographystyle{abbrv}
\bibliography{references}
\end{document}
